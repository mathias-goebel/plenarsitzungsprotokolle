Frau Präsidentin! Meine Damen und Herren! Es ist gut, dass wir erneut zu Fragen der künstlichen Intelligenz beraten. Anlass geben nicht nur der Verhandlungsverlauf zur Regulierung von künstlicher Intelligenz auf EU-Ebene, sondern auch jüngste Erkenntnisse aus KI-Anwendungen, die wir nicht ignorieren sollten.
So galt bislang ChatGPT immer wieder als besonders positives Anwendungsbeispiel für KI. Nun aber haben Forschungen von AlgorithmWatch gemeinsam mit IA-Forensics gezeigt, dass der Chatbot beispielsweise Fragen zu den Landtagswahlen in Bayern und Hessen falsch und mit irreführenden Inhalten beantwortet hat.
Das ist demokratiegefährdend, und deshalb können wir nicht einfach über solche Entwicklungen hinweggehen.
Zudem – auch das will ich an den Anfang meiner Rede stellen; Kollege Marvi von der SPD und Tabea Rößner von den Bündnisgrünen haben gerade darauf hingewiesen – stellt eigenartigerweise der Unionsantrag das vom EU-Parlament eingeführte Kriterium „Umwelt“ infrage. Das verstehe ich überhaupt nicht.
– Sie wollen es sogar streichen; das steht in Ihrem Antrag.
Dabei ist doch bekannt, dass KI-Nutzung einen immens hohen Strom- und Wasserverbrauch verursacht. Nachhaltigkeit und Klimaneutralität müssen angesichts der Klimaziele der UN und Deutschlands
mittelfristig wesentlich über die Förderung und den Einsatz neuer Technologien, also auch von KI, entscheiden.
Die Linke schlägt weiterführend vor, dass gemeinwohlorientierte, also nichtkommerzielle Anwendungen gestärkt werden. Und natürlich sollen diese auch auf verlässlichen sogenannten Grundlagenmodellen basieren können. Die Kollegen haben es schon erwähnt: Aktuell sind es jedoch die großen Techunternehmen, die solche Grundlagenmodelle anbieten. Es kann also nicht verwundern, dass wir diese auch in die Pflicht nehmen wollen, wenn es darum geht, Risiken von KI-Anwendungen zu begrenzen. Das muss verbindlich geregelt werden.
KI-Anwendungen im Sinne des Gemeinwohls gibt es beispielsweise in Behörden, in Schulen, kleinen Unternehmen oder eben auch in Nichtregierungsorganisationen. Und diese agieren oftmals im Grundrechtsbereich, oder sie bemühen sich beispielsweise aktiv um den Schutz von Grundrechten. Aktuell sollen bezüglich der Grundlagenmodelle diese Akteure aber deutlich stärker belastet werden als die großen Techkonzerne. Für diese stehen sogar Ausnahmen in Aussicht, beispielsweise bei Anwendungen im Hochrisikobereich; also sie können sich dort sozusagen selbst einschätzen. Aktuell ist die Verordnung so formuliert, dass sie den Techkonzernen damit Schlupflöcher öffnet, Grundrechte einzuschränken. Das ist vollkommen inakzeptabel.
– Ja, ja.
Die Öffentlichkeit kann derzeit kaum überblicken, was gerade zur KI-Verordnung verhandelt wird. Und mit welchen Positionen die Bundesregierung sich dort einbringt, bleibt ebenso intransparent. Das zeigen die Antworten der Bundesregierung auf unsere Kleine Anfrage.
Damit werden die Kontrollrechte des Parlaments, aber eben auch Informationsansprüche der Bevölkerung unterlaufen. Auch das ist inakzeptabel.
Statt weiterer Regulierungsausnahmen bedarf es schnell verbindlicher Regeln und Definitionen. Würden Sie sich beispielsweise stärker an unseren Vorschlägen oder verschiedener demokratischer, zivilgesellschaftlicher Organisationen orientieren, gäbe es mehr Vertrauenswürdigkeit für KI, sicherere Anwendungen und besseren Grundrechtsschutz. Wieso, um Gottes willen, soll das ein Innovationsnachteil sein? Das wäre doch eher ein Marktvorteil für europäische Modelle.
Fazit: Es muss an Werkzeugen gegen den Missbrauch von KI viel stärker geforscht werden, Zulassungsverfahren müssen verbindlicher werden. Es müssen gemeinwohlorientierte Anwendungen gestärkt werden. Und schließlich müssen Erklärungs- und Mitbestimmungsrechte bei Entscheidungen, die auf KI-Nutzung folgen, etabliert werden.
Besten Dank.Frau Präsidentin! Meine Damen und Herren! Es ist gut, dass wir erneut zu Fragen der künstlichen Intelligenz beraten. Anlass geben nicht nur der Verhandlungsverlauf zur Regulierung von künstlicher Intelligenz auf EU-Ebene, sondern auch jüngste Erkenntnisse aus KI-Anwendungen, die wir nicht ignorieren sollten.
So galt bislang ChatGPT immer wieder als besonders positives Anwendungsbeispiel für KI. Nun aber haben Forschungen von AlgorithmWatch gemeinsam mit IA-Forensics gezeigt, dass der Chatbot beispielsweise Fragen zu den Landtagswahlen in Bayern und Hessen falsch und mit irreführenden Inhalten beantwortet hat.
Das ist demokratiegefährdend, und deshalb können wir nicht einfach über solche Entwicklungen hinweggehen.
Zudem – auch das will ich an den Anfang meiner Rede stellen; Kollege Marvi von der SPD und Tabea Rößner von den Bündnisgrünen haben gerade darauf hingewiesen – stellt eigenartigerweise der Unionsantrag das vom EU-Parlament eingeführte Kriterium „Umwelt“ infrage. Das verstehe ich überhaupt nicht.
– Sie wollen es sogar streichen; das steht in Ihrem Antrag.
Dabei ist doch bekannt, dass KI-Nutzung einen immens hohen Strom- und Wasserverbrauch verursacht. Nachhaltigkeit und Klimaneutralität müssen angesichts der Klimaziele der UN und Deutschlands
mittelfristig wesentlich über die Förderung und den Einsatz neuer Technologien, also auch von KI, entscheiden.
Die Linke schlägt weiterführend vor, dass gemeinwohlorientierte, also nichtkommerzielle Anwendungen gestärkt werden. Und natürlich sollen diese auch auf verlässlichen sogenannten Grundlagenmodellen basieren können. Die Kollegen haben es schon erwähnt: Aktuell sind es jedoch die großen Techunternehmen, die solche Grundlagenmodelle anbieten. Es kann also nicht verwundern, dass wir diese auch in die Pflicht nehmen wollen, wenn es darum geht, Risiken von KI-Anwendungen zu begrenzen. Das muss verbindlich geregelt werden.
KI-Anwendungen im Sinne des Gemeinwohls gibt es beispielsweise in Behörden, in Schulen, kleinen Unternehmen oder eben auch in Nichtregierungsorganisationen. Und diese agieren oftmals im Grundrechtsbereich, oder sie bemühen sich beispielsweise aktiv um den Schutz von Grundrechten. Aktuell sollen bezüglich der Grundlagenmodelle diese Akteure aber deutlich stärker belastet werden als die großen Techkonzerne. Für diese stehen sogar Ausnahmen in Aussicht, beispielsweise bei Anwendungen im Hochrisikobereich; also sie können sich dort sozusagen selbst einschätzen. Aktuell ist die Verordnung so formuliert, dass sie den Techkonzernen damit Schlupflöcher öffnet, Grundrechte einzuschränken. Das ist vollkommen inakzeptabel.
– Ja, ja.
Die Öffentlichkeit kann derzeit kaum überblicken, was gerade zur KI-Verordnung verhandelt wird. Und mit welchen Positionen die Bundesregierung sich dort einbringt, bleibt ebenso intransparent. Das zeigen die Antworten der Bundesregierung auf unsere Kleine Anfrage.
Damit werden die Kontrollrechte des Parlaments, aber eben auch Informationsansprüche der Bevölkerung unterlaufen. Auch das ist inakzeptabel.
Statt weiterer Regulierungsausnahmen bedarf es schnell verbindlicher Regeln und Definitionen. Würden Sie sich beispielsweise stärker an unseren Vorschlägen oder verschiedener demokratischer, zivilgesellschaftlicher Organisationen orientieren, gäbe es mehr Vertrauenswürdigkeit für KI, sicherere Anwendungen und besseren Grundrechtsschutz. Wieso, um Gottes willen, soll das ein Innovationsnachteil sein? Das wäre doch eher ein Marktvorteil für europäische Modelle.
Fazit: Es muss an Werkzeugen gegen den Missbrauch von KI viel stärker geforscht werden, Zulassungsverfahren müssen verbindlicher werden. Es müssen gemeinwohlorientierte Anwendungen gestärkt werden. Und schließlich müssen Erklärungs- und Mitbestimmungsrechte bei Entscheidungen, die auf KI-Nutzung folgen, etabliert werden.
Besten Dank.