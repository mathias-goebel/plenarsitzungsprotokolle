Sehr geehrte Frau Präsidentin! Liebe Kolleginnen und Kollegen! Lange Zeit fristete das Thema „künstliche Intelligenz“ eher ein Nischendasein. Das hat sich in der Tat mit dem Hype um generative KI vor einem knappen Jahr durch die Veröffentlichung von GPT-3.5 fundamental verändert. Seitdem hat die Technologie überall Einzug gehalten: in den Medien, auf politischen Panels, im Büro und sogar beim Abendbrot zu Hause. Anwendungen wie ChatGPT faszinieren, nicht nur wegen ihres Könnens, sondern auch, weil sie KI auf einmal und für alle einfach nutzbar machen.
Gleichzeitig sehen wir aber auch erhebliche Risiken, die von generativer KI ausgehen. Dazu zählen Falsch- und Desinformation, Verstärkung von Diskriminierung und Marginalisierung, die Verbreitung persönlicher, sensibler Informationen bis hin zu unzähligen Clickworkerinnen und Clickworkern im Globalen Süden, die sich im Dienst der Unternehmen sozusagen als menschliche Filter für diese Technologien traumatisierende Inhalte anschauen müssen.
Es geht für uns darum, fantastische Potenziale von Zukunftstechnologien wie KI zu fördern – selbstverständlich; und von denen gibt es eine ganze Menge –, aber bei dieser Faszination nicht an der Seitenlinie stehen zu bleiben, sondern als Politik, Wirtschaft und Gesellschaft auch einen verantwortungsvollen Umgang mit KI zu finden. Das nennt man klassischerweise Risikofolgenabschätzung, und dafür sind wir im Parlament und als Politik verdammt noch mal zuständig, liebe Kolleginnen und Kollegen.
Deshalb haben wir ja gewichtige Stimmen aus Wissenschaft, Gesellschaft und auch aus der Wirtschaft, die sich abseits von fragwürdigen Forderungen nach Entwicklungsstopps und Moratorien kritisch zu aktuellen Entwicklungen im Bereich künstlicher Intelligenz äußern. Vom Forscher bis zum Entwickler, viele sind sich einig: Wir brauchen verbindliche Regeln für KI. Nur dann gelingt eine vertrauenswürdige und sichere Technologie, die uns Menschen dient und die mehr Akzeptanz in Gesellschaft und Wirtschaft findet.
Das ist das Setting für den risikobasierten, wertebezogenen Regulierungsansatz für KI auf europäischer Ebene, dessen Verhandlung und Beratung sich jetzt mit dem Trilog auf ein abschließendes Ergebnis hinbewegen. Ja, selbst die Europäische Volkspartei und auch Ihre eigenen Unionsabgeordneten im Europäischen Parlament stellen diese Regulierung nicht grundsätzlich in Frage,
und die Europäische Kommission und die Kommissionspräsidentin Ursula von der Leyen erst recht nicht.
Wir sind jedenfalls sehr froh darüber, dass es zu dieser KI-Regulierung auf europäischer Ebene kommen wird, die ein weltweit einzigartiges Regelwerk schafft, das dazu beitragen wird, dass es künftig mehr Modelle dieser Art weltweit geben wird, und das uns auch auf dem Weg hin zu der dringend benötigten internationalen Kooperation bei KI-Normen und KI-Standards helfen wird. Es ist ausdrücklich gut, dass wir als Europäerinnen und Europäer hier gemeinsam vorangehen, liebe Kolleginnen und Kollegen.
Ihr Antrag – und ich habe ihn genau gelesen – ist es wert, dass wir darüber reden – selbstverständlich. Man könnte zu vielen Thesen etwas entgegnen. Ich will beispielhaft drei Bereiche hervorheben.
Erstens: Forschung und Entwicklung. Die Unionsfraktion fordert mit Blick auf die KI-Verordnung mehr Ausnahmen für diesen Bereich.
Das klingt erst mal zum Wohlfühlen:
Freiheit für Forschung und Entwicklung, bloß nicht zu viel regulieren; das wollen Sie damit vermutlich sagen. Dann muss man das Ganze aber auch gesamthaft betrachten. Auch OpenAI ist einst als gemeinnützige Forschungsorganisation gestartet.
Ein paar Jahre und viele Milliarden US-Dollar später dominiert das Unternehmen den Markt.
Wie gehen wir mit einer solchen Kommerzialisierung um? Ebendieses Problem wird von Ihnen nach meinem Dafürhalten nicht ausreichend betrachtet, liebe Kolleginnen und Kollegen.
Zweitens: Ihre Einlassungen zum Thema Urheberrecht. Das Europäische Parlament hat in seinem Beschluss Mitte Juni vorgeschlagen, dass Unternehmen offenlegen müssen, mit welchem urheberrechtlich geschützten Material sie ihre Systeme trainieren.
Wir unterstützen das. Aber das kann nur ein erster Schritt sein, um dem Ungleichgewicht zwischen Kreativen und Unternehmen zu begegnen. Denn das Geschäftsmodell der Big-Tech-Unternehmen wird aktuell zu einer echten Bedrohung der beruflichen Existenz von Kreativen und Kulturschaffenden.
Nach dem Willen der Union, also laut Ihrem Antrag, soll das Thema Urheberrecht aber gar keinen Platz in der KI-Verordnung bekommen. Sie glauben, das sei einfach nicht der richtige Ort. Stattdessen wird auf die Urheberrichtlinie verwiesen.
Darüber, wie genau dort eine geeignete Regelung angesichts offener Fragen wie etwa beim Thema Data-Mining aussehen könnte, lassen Sie uns noch im Dunkeln, liebe Kolleginnen und Kollegen.
Drittens: das Thema Umweltschutz. Recherchen haben gezeigt, dass allein für das Training von GPT-3 so viel Strom aufgewendet worden ist, wie 200 Menschen in einem Jahr verbrauchen, und so viel Wasser, wie über 5 000 Menschen am Tag trinken. Dazu kommt das, was der tägliche Betrieb aufzehrt. Trotzdem setzt sich die Union dafür ein, dass wir Bestimmungen aus dem Beschluss des Europäischen Parlaments zur KI-Verordnung, die auf Transparenz und Eindämmung der Ressourcennutzung abzielen, fallen lassen. Ein verantwortungsvoller Umgang mit der Technologie darf aber den Umweltschutz nicht aussparen.
Deshalb müssen wir die Unternehmen hier in die Pflicht nehmen, liebe Kolleginnen und Kollegen.
Was wir jetzt brauchen, ist keine Fundamentalkritik am AI Act quasi in letzter Sekunde. Wir brauchen aktive und konstruktive Mitarbeit auf den letzten Metern der Verhandlungen, um die KI-Verordnung noch besser zu machen und noch an den wichtigen Stellschrauben zu drehen. Da sind wir auf dem Weg. Selbstverständlich müssen wir heute auch schon sehr stark über eine kluge Umsetzung einer KI-Governance nachdenken, die ja dann entscheidend sein wird.
Wir sind uns sicher: So werden wir als Teil der Europäischen Union nicht nur die Ersten sein, die eine umfassende Regulierung der KI auf die Beine stellen, sondern auch global zum Vorbild für andere Staaten im Umgang mit künstlicher Intelligenz werden. An diesem Projekt wollen wir gerne mitarbeiten.
Vielen Dank.