Frau Präsidentin! Liebe Kolleginnen und Kollegen! Angesichts der Art und Weise, wie der Kollege Renner von der AfD eine Verschwörung von uns allen
                    gegen die künstliche Intelligenz abgeleitet hat, muss ich zwingend schlussfolgern, dass natürliche Intelligenz offensichtlich kein Apriori ist.
Deswegen ist es umso wichtiger, differenziert über künstliche Intelligenz zu sprechen, was Sie aber nicht getan haben. Wir stellen nämlich dabei fest,
                    dass wir gleichzeitig zu einer Unterschätzung und Überschätzung der ganzen Fragestellungen von künstlicher Intelligenz in Bezug auf Meinungsbildung
                    tendieren.
Zunächst wird ziemlich klar, dass wir uns in den Versuchen, uns zu orientieren, noch in der Phase der Digitalisierung, aber nicht wirklich der
                    Digitalität bewegen; das macht der Bericht sehr deutlich. Es geht nicht nur um eine Transformation der Kommunikationsformen, sondern auch um die Art und Weise,
                    wie Gesellschaft entsteht, um die Art und Weise, wie Menschen sich verbinden, im privaten Raum, aber auch im öffentlichen Raum, und inwieweit tatsächlich, ohne
                    dass hinreichende Erkenntnisse vorliegen, eine individuelle Meinungsbildung entsteht, gleichzeitig aber auch öffentliche Meinungsbildung erfolgt. All das
                    bedeutet, dass wir es auch mit einer fundamentalen gesellschaftlichen Veränderung zu tun haben.
Diese fundamentale gesellschaftliche Veränderung ist aber weder im Modus der Dämonisierung noch der Glorifizierung zu regeln. Auch das wird sehr
                    deutlich. Vielmehr ist gefragt, einerseits genau zu schauen: Wo brauchen wir mehr Transparenz in Bezug auf die Algorithmen, aber auch auf die Daten, auf das,
                    was an Zielen vorgegeben wird? Diese Form von Öffentlichkeit folgt nämlich gewinnorientierten Regeln und eben nicht journalistischen Prinzipien, um
                    Öffentlichkeit zu schaffen. Andererseits brauchen wir aber auch einen Blick darauf, wo es gar nicht sinnvoll ist, regulatorisch zu wirken, wo es etwa sinnvoll
                    sein kann, gerade keine Vielfalt zu verordnen, sondern über Anreize, über Nudging subtilere Wege zu finden, die an der Verhaltensökonomie orientiert sind.
Daher ist ein differenzierter Blick notwendig. Wir sind oft aber eher Nichtschwimmer, die Schwimmern – politisch – vormachen wollen, wie Schwimmen
                    funktioniert und wie die Regeln bestimmt werden sollen. Das müssen wir ganz nüchtern und ehrlich anerkennen. Allerdings – und das ist die Überschätzung des
                    Prozesses von künstlicher Intelligenz – ist es so – und das hat Herr Renner bewiesen –, dass die größte Gefährdung von Meinungsvielfalt, übrigens die größte
                    Gefährdung der Zivilisation überhaupt, nicht künstliche Intelligenz ist, sondern der Mensch. Der Mensch ist nämlich Subjekt wie Objekt dieser Prozesse, und es
                    liegt am Ende an ihm und an den Gruppen und an der Intention. Das macht Desinformation deutlich.
Kampagnen haben Intentionen und Zwecke. Es gibt dort Akteure, die die Prinzipien von KI nutzen, die Algorithmen nutzen und deren verstärkende
                    Funktion, um entsprechend auf die Meinungsbildung Einfluss zu nehmen. Das ist genau der Ansatzpunkt. Wir brauchen Menschen, die die Prinzipien verstehen, die
                    kompetent sind, die wissen, was ihnen vorgesetzt wird, die wissen, dass sie Gegenstand von gewinnorientierten, gewinnbasierten Kalkülen sind, und die
                    gleichzeitig kompetent sind, damit umzugehen. Diese Menschen müssen aber, wenn sie Desinformation und Hassrede erfahren – und das ist nicht die Ausnahme,
                    sondern das ist die Regel heutzutage –, auch Solidarität erfahren. Denn das ist kein Problem der künstlichen Intelligenz, sondern eine Problematik, die oft mit
                    fehlender Solidarität und fehlender Nutzung der Mittel auch im digitalen Raum zu tun hat, wenn es darum geht, Solidarität zu schaffen.
Mein letzter Punkt. Ich glaube, wir tun gut daran, die Emanzipationspotenziale, die in dieser Digitalität liegen, zu nutzen. Ganz viele, die in der
                    Vergangenheit nicht die Möglichkeit hatten, ihre Meinung zu äußern, die nicht gehört wurden, deren Stimmen nicht wahrnehmbar waren, haben nun die Möglichkeit,
                    teilzuhaben. Deshalb ist gesellschaftliche Modernität mithilfe von Digitalität doch das, was wir uns vorschreiben sollten. Und dann habe ich auch wieder
                    Hoffnung, dass natürliche Intelligenz doch ein Apriori ist.
Vielen Dank.Frau Präsidentin! Liebe Kolleginnen und Kollegen! Angesichts der Art und Weise, wie der Kollege Renner von der AfD eine Verschwörung von uns allen
                    gegen die künstliche Intelligenz abgeleitet hat, muss ich zwingend schlussfolgern, dass natürliche Intelligenz offensichtlich kein Apriori ist.
Deswegen ist es umso wichtiger, differenziert über künstliche Intelligenz zu sprechen, was Sie aber nicht getan haben. Wir stellen nämlich dabei fest,
                    dass wir gleichzeitig zu einer Unterschätzung und Überschätzung der ganzen Fragestellungen von künstlicher Intelligenz in Bezug auf Meinungsbildung
                    tendieren.
Zunächst wird ziemlich klar, dass wir uns in den Versuchen, uns zu orientieren, noch in der Phase der Digitalisierung, aber nicht wirklich der
                    Digitalität bewegen; das macht der Bericht sehr deutlich. Es geht nicht nur um eine Transformation der Kommunikationsformen, sondern auch um die Art und Weise,
                    wie Gesellschaft entsteht, um die Art und Weise, wie Menschen sich verbinden, im privaten Raum, aber auch im öffentlichen Raum, und inwieweit tatsächlich, ohne
                    dass hinreichende Erkenntnisse vorliegen, eine individuelle Meinungsbildung entsteht, gleichzeitig aber auch öffentliche Meinungsbildung erfolgt. All das
                    bedeutet, dass wir es auch mit einer fundamentalen gesellschaftlichen Veränderung zu tun haben.
Diese fundamentale gesellschaftliche Veränderung ist aber weder im Modus der Dämonisierung noch der Glorifizierung zu regeln. Auch das wird sehr
                    deutlich. Vielmehr ist gefragt, einerseits genau zu schauen: Wo brauchen wir mehr Transparenz in Bezug auf die Algorithmen, aber auch auf die Daten, auf das,
                    was an Zielen vorgegeben wird? Diese Form von Öffentlichkeit folgt nämlich gewinnorientierten Regeln und eben nicht journalistischen Prinzipien, um
                    Öffentlichkeit zu schaffen. Andererseits brauchen wir aber auch einen Blick darauf, wo es gar nicht sinnvoll ist, regulatorisch zu wirken, wo es etwa sinnvoll
                    sein kann, gerade keine Vielfalt zu verordnen, sondern über Anreize, über Nudging subtilere Wege zu finden, die an der Verhaltensökonomie orientiert sind.
Daher ist ein differenzierter Blick notwendig. Wir sind oft aber eher Nichtschwimmer, die Schwimmern – politisch – vormachen wollen, wie Schwimmen
                    funktioniert und wie die Regeln bestimmt werden sollen. Das müssen wir ganz nüchtern und ehrlich anerkennen. Allerdings – und das ist die Überschätzung des
                    Prozesses von künstlicher Intelligenz – ist es so – und das hat Herr Renner bewiesen –, dass die größte Gefährdung von Meinungsvielfalt, übrigens die größte
                    Gefährdung der Zivilisation überhaupt, nicht künstliche Intelligenz ist, sondern der Mensch. Der Mensch ist nämlich Subjekt wie Objekt dieser Prozesse, und es
                    liegt am Ende an ihm und an den Gruppen und an der Intention. Das macht Desinformation deutlich.
Kampagnen haben Intentionen und Zwecke. Es gibt dort Akteure, die die Prinzipien von KI nutzen, die Algorithmen nutzen und deren verstärkende
                    Funktion, um entsprechend auf die Meinungsbildung Einfluss zu nehmen. Das ist genau der Ansatzpunkt. Wir brauchen Menschen, die die Prinzipien verstehen, die
                    kompetent sind, die wissen, was ihnen vorgesetzt wird, die wissen, dass sie Gegenstand von gewinnorientierten, gewinnbasierten Kalkülen sind, und die
                    gleichzeitig kompetent sind, damit umzugehen. Diese Menschen müssen aber, wenn sie Desinformation und Hassrede erfahren – und das ist nicht die Ausnahme,
                    sondern das ist die Regel heutzutage –, auch Solidarität erfahren. Denn das ist kein Problem der künstlichen Intelligenz, sondern eine Problematik, die oft mit
                    fehlender Solidarität und fehlender Nutzung der Mittel auch im digitalen Raum zu tun hat, wenn es darum geht, Solidarität zu schaffen.
Mein letzter Punkt. Ich glaube, wir tun gut daran, die Emanzipationspotenziale, die in dieser Digitalität liegen, zu nutzen. Ganz viele, die in der
                    Vergangenheit nicht die Möglichkeit hatten, ihre Meinung zu äußern, die nicht gehört wurden, deren Stimmen nicht wahrnehmbar waren, haben nun die Möglichkeit,
                    teilzuhaben. Deshalb ist gesellschaftliche Modernität mithilfe von Digitalität doch das, was wir uns vorschreiben sollten. Und dann habe ich auch wieder
                    Hoffnung, dass natürliche Intelligenz doch ein Apriori ist.
Vielen Dank.