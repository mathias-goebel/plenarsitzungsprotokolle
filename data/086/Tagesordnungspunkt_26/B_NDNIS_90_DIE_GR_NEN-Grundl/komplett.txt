Frau Präsidentin! Meine Damen und Herren! Ich zitiere: Wir befinden uns in einer Zeit, in der Algorithmen unser tägliches Leben beeinflussen. Sie
                    beeinflussen, was wir kaufen, was wir sehen, was wir lesen und was wir denken. Aber wie wirken sich diese Algorithmen auf die öffentliche Meinungsbildung aus? –
                    Diese einleitenden Worte und diese Frage sind von ChatGPT. Dabei erfindet die KI nicht selbst, sondern sie spiegelt die aktuelle gesellschaftliche Debatte im
                    Netz wider, hier eben die Debatte über sich selbst.
Circa 65 Prozent der Deutschen schauen, lesen, hören Nachrichten auch im Internet. Für 46 Prozent der 18- bis 24-Jährigen ist das Internet inzwischen
                    die einzige Quelle von Informationen über das Weltgeschehen. Von 55 Prozent der Menschen – ich bin gleich fertig mit den Zahlen – werden redaktionell
                    erarbeitete Seiten genutzt, wie „Spiegel Online“ oder „Zeit Online“. Oder eben Suchmaschinen und Facebook, die mit Algorithmen eine Nachrichtenselektion
                    vornehmen. Algorithmen können also eine wichtige Funktion für den Zugang zu Nachrichten haben – Tendenz steigend.
In einer immer komplexer werdenden Welt kann künstliche Intelligenz große Datenmengen filtern, priorisieren und Zusammenhänge herstellen. Sie kann
                    Dinge vereinfachen, sie kann aber auch, wie aktuell in Russland, das Netz nach kritischen Kommentaren oder Protestaufrufen durchforsten und diese herausfiltern.
                    „Sauberes Internet“ wird das dann genannt.
Die Priorisierung nach Klicks führt dazu, dass schrille Beiträge im Newsfeed nach oben geschwemmt werden. Das führt nicht zu Ausgewogenheit, sondern
                    zu Skandalisierung und Verhetzung. Algorithmen können damit zur Verbreitung von Desinformationen beitragen.
Als Kulturpolitiker füge ich an: Nach einem Bericht von „digital pioneers“ können Musiklabels in Zukunft Einfluss auf die Spotify-Algorithmen nehmen.
                    Was Ihnen dann zum Anhören empfohlen wird, orientiert sich primär an wirtschaftlichen Interessen. Das passiert auch heute schon. Diese Einflussnahme – und das
                    ist nur ein Beispiel – dürfen wir gerade im Hinblick auf den Erhalt einer vielfältigen Kulturlandschaft nicht akzeptieren.
Es stellen sich die Fragen: Welche Daten hat ChatGPT eigentlich genutzt, um die Einleitung zu produzieren? Nach welchen Kriterien werden Informationen
                    vom Algorithmus sortiert? Welche Ziele verfolgen die Macher/‑innen mit der Festlegung dieser Kriterien? Was lassen sie weg? Und schließlich: Wer sind die
                    Geldgeber/-innen des Unternehmens? Vieles davon ist unklar, und das ist ein Problem. Wir wissen zu wenig über die Kriterien und Quellen der Algorithmen. Damit
                    entstehen Handlungsräume für Manipulationen.
Was wir brauchen, um Manipulationen entgegenzuwirken, ist eine demokratische Mitbestimmung über Algorithmen. Das ist allerdings voraussetzungsvoll, so
                    das Fazit des Gutachtens. Wer kein Wissen über die Strukturen hinter den Algorithmen hat, kann sie nicht mitbestimmen. Darum, die Selbstbestimmtheit der
                    Nutzer/-innen zu stärken, muss es aber gehen.
Algorithmen können eine Chance sein, Informationen schneller, niedrigschwellig, demokratischer und selbstbestimmter zugänglich zu machen. Das kann
                    gelingen, wenn sie demokratischer Kontrolle unterliegen, und dafür müssen wir sorgen.
Vielen Dank.Frau Präsidentin! Meine Damen und Herren! Ich zitiere: Wir befinden uns in einer Zeit, in der Algorithmen unser tägliches Leben beeinflussen. Sie
                    beeinflussen, was wir kaufen, was wir sehen, was wir lesen und was wir denken. Aber wie wirken sich diese Algorithmen auf die öffentliche Meinungsbildung aus? –
                    Diese einleitenden Worte und diese Frage sind von ChatGPT. Dabei erfindet die KI nicht selbst, sondern sie spiegelt die aktuelle gesellschaftliche Debatte im
                    Netz wider, hier eben die Debatte über sich selbst.
Circa 65 Prozent der Deutschen schauen, lesen, hören Nachrichten auch im Internet. Für 46 Prozent der 18- bis 24-Jährigen ist das Internet inzwischen
                    die einzige Quelle von Informationen über das Weltgeschehen. Von 55 Prozent der Menschen – ich bin gleich fertig mit den Zahlen – werden redaktionell
                    erarbeitete Seiten genutzt, wie „Spiegel Online“ oder „Zeit Online“. Oder eben Suchmaschinen und Facebook, die mit Algorithmen eine Nachrichtenselektion
                    vornehmen. Algorithmen können also eine wichtige Funktion für den Zugang zu Nachrichten haben – Tendenz steigend.
In einer immer komplexer werdenden Welt kann künstliche Intelligenz große Datenmengen filtern, priorisieren und Zusammenhänge herstellen. Sie kann
                    Dinge vereinfachen, sie kann aber auch, wie aktuell in Russland, das Netz nach kritischen Kommentaren oder Protestaufrufen durchforsten und diese herausfiltern.
                    „Sauberes Internet“ wird das dann genannt.
Die Priorisierung nach Klicks führt dazu, dass schrille Beiträge im Newsfeed nach oben geschwemmt werden. Das führt nicht zu Ausgewogenheit, sondern
                    zu Skandalisierung und Verhetzung. Algorithmen können damit zur Verbreitung von Desinformationen beitragen.
Als Kulturpolitiker füge ich an: Nach einem Bericht von „digital pioneers“ können Musiklabels in Zukunft Einfluss auf die Spotify-Algorithmen nehmen.
                    Was Ihnen dann zum Anhören empfohlen wird, orientiert sich primär an wirtschaftlichen Interessen. Das passiert auch heute schon. Diese Einflussnahme – und das
                    ist nur ein Beispiel – dürfen wir gerade im Hinblick auf den Erhalt einer vielfältigen Kulturlandschaft nicht akzeptieren.
Es stellen sich die Fragen: Welche Daten hat ChatGPT eigentlich genutzt, um die Einleitung zu produzieren? Nach welchen Kriterien werden Informationen
                    vom Algorithmus sortiert? Welche Ziele verfolgen die Macher/‑innen mit der Festlegung dieser Kriterien? Was lassen sie weg? Und schließlich: Wer sind die
                    Geldgeber/-innen des Unternehmens? Vieles davon ist unklar, und das ist ein Problem. Wir wissen zu wenig über die Kriterien und Quellen der Algorithmen. Damit
                    entstehen Handlungsräume für Manipulationen.
Was wir brauchen, um Manipulationen entgegenzuwirken, ist eine demokratische Mitbestimmung über Algorithmen. Das ist allerdings voraussetzungsvoll, so
                    das Fazit des Gutachtens. Wer kein Wissen über die Strukturen hinter den Algorithmen hat, kann sie nicht mitbestimmen. Darum, die Selbstbestimmtheit der
                    Nutzer/-innen zu stärken, muss es aber gehen.
Algorithmen können eine Chance sein, Informationen schneller, niedrigschwellig, demokratischer und selbstbestimmter zugänglich zu machen. Das kann
                    gelingen, wenn sie demokratischer Kontrolle unterliegen, und dafür müssen wir sorgen.
Vielen Dank.