Sehr geehrte Frau Präsidentin! Liebe Kolleginnen und Kollegen der demokratischen Fraktionen! Sehr geehrte Damen und Herren! Immer wenn ich gefragt werde: „Was machst du eigentlich im Digitalausschuss?“, kann ich sagen: Alles, was mit Daten zu tun hat – von Datenschutz bis Open Data, von Dateninfrastrukturen bis Datenverarbeitung, von Daten-Clouds bis Data-Mining.
Wir befinden uns in einer wahnsinnig spannenden digitalpolitischen Zeit. Wir müssen uns nämlich die Frage stellen: In welcher digitalen Welt wollen wir leben? Dazu gehört auch, dass wir uns die Folgen von technischen Neuerungen ansehen und Gesetzeslücken schließen. Um diese Lücken zu finden, ist oftmals tiefe Expertise nötig. Die haben wir uns jetzt über das Büro für Technikfolgen-Abschätzung zum Thema Data-Mining eingeholt, dem ich an dieser Stelle auch recht herzlich für den Bericht danken möchte.
Also lassen Sie uns kurz eintauchen in die spannende Welt der Daten! Was ist eigentlich Data-Mining? Was sind die Chancen? Was sind die Risiken? Was müssen wir in Zukunft beachten? Unter Data-Mining versteht man das automatisierte Erkennen von Mustern in großen Datenmengen. Ein gern genutztes Beispiel – Kollegin Hoppermann hat es schon angebracht – ist das automatisierte Erkennen von Krebszellen auf Mammografie-Screenings. Was braucht es dafür? Natürlich viele, viele Daten! Aus den vergangenen Jahrzehnten haben wir Massen an Daten in diesem konkreten Beispiel: Bilder von Gewebe, in dem sich entweder ein Tumor befindet oder eben nicht. Diese Daten, diese Bilder müssen klassifiziert sein. Ist hier ein Tumor zu sehen, ja oder nein? Sind wir uns unsicher?
In unseren Trainingsdaten existieren diese Bilder, jeweils klassifiziert von Ärztinnen und Ärzten, also von Expertinnen und Experten. Hat man genügend dieser Bilder mit entsprechenden Befunden, kann ein Algorithmus mit diesen Daten trainiert werden. Er kann anhand der Bilder lernen, wie ein Tumor aussieht. Er erkennt also Muster und imitiert diese. Schließlich kann man diesen trainierten Algorithmus dann auf unbekannte Bilder anwenden und die Frage stellen: Ist hier ein Tumor zu sehen, ja oder nein? Der Algorithmus kann angeben, wie sicher auf diesem neuen Bild ein Tumor zu sehen ist. Jetzt schauen die Expertinnen und Experten noch mal drauf, um zu überprüfen, ob der Algorithmus die Muster richtig erkannt hat, und damit lernt er wieder.
Dieser Vorgang wird auch „Machine Learning“, also „maschinelles Lernen“, genannt. Wir bringen einem Computerprogramm bei, anhand von vorhandenen Daten Muster zu erkennen, die es dann in neuen Kontexten wiederfinden kann. Wir alle trainieren übrigens Algorithmen, sind also quasi Expertinnen und Experten, wenn wir die Bildchen mit dem Zebrastreifen oder den Ampeln anklicken, um zu bestätigen, dass wir keine Roboter sind. Es gibt unzählige Beispiele aus dem Bereich Data-Mining, und angewendet werden diese Methoden auch heute schon in vielen Kontexten.
Wo liegen also die Chancen? Die liegen überall dort, wo Datenmengen so groß sind, dass ein Mensch sie nicht mehr verarbeiten kann, überall dort, wo Muster so komplex sind, dass Menschen sie nicht überblicken, und überall dort, wo Prozesse so schnell ablaufen müssen, dass Menschen zu langsam wären, um sie zu bearbeiten.
Aber wo Licht ist, ist auch Schatten. Also schauen wir uns mal die Risiken an! Die liegen überall dort, wo personenbezogene Daten erhoben werden; da ist nämlich Vorsicht geboten. Wenn sie einmal geleakt wurden, sind Daten schwer wieder einzufangen. Wir als Einzelpersonen haben oft gar nicht die Möglichkeiten, unsere Daten zu schützen, wenn sie bei anderen Infrastrukturen liegen. Deswegen müssen personenbezogene Daten ordentlich anonymisiert und mit Vorsicht behandelt werden.
Auch gibt es beim Data-Mining eine ungleiche Verteilung in der Nutzung. Das Know-how, Kapital und Profite der Datennutzung liegen oft in der Wirtschaft. Staat und Zivilgesellschaft profitieren nicht im gleichen Maße, obwohl sie einen Großteil der Primärdaten zur Verfügung stellen. Weiterhin ist die Qualitätssicherung oft unklar. Wir wissen nicht, wie welche Algorithmen arbeiten, auf welchen Daten sie trainiert wurden. Und genau das sehen wir gerade bei ChatGPT. Teilweise erzählt es einem einen ganz schönen Schmu; aber ohne Quellenangabe und ohne Kennzeichnungspflicht für algorithmische Entscheidungen, Bilder und grundsätzlich KI-generierte Inhalte kann ich das nicht einfach nachvollziehen.
Ein riesiges Problem bei Algorithmen und algorithmischen Entscheidungen ist die vermeintliche Objektivität. Kann eine Maschine, ein Algorithmus rassistisch sein, kann sie diskriminieren? Grundsätzlich ja, aber nicht willentlich! Denn Maschinen und Algorithmen sind nur so objektiv wie die Daten, die wir ihnen zur Verfügung stellen, mit denen wir sie trainieren. Und sind diese Daten rassistisch, sexistisch, ableistisch, antisemitisch, weil sie eine Welt abbilden, die diese Züge hat, lernt eine Maschine, genau diese Muster zu reproduzieren, unter dem Deckmantel der vermeintlich mathematischen Objektivität.
So, was machen wir jetzt damit? Wir müssen uns im Klaren sein: Data-Mining ist in vollem Gange; das ist keine Zukunftsmusik. Wir trainieren jeden Tag Algorithmen und Maschinen mit unseren Daten. Und ChatGPT gibt uns inzwischen teilweise bessere Antworten als so manch ein menschlicher Gesprächspartner. Wir werden diese Entwicklung nicht mehr aufhalten, und das sollten wir auch nicht versuchen. Wir sollten aber versuchen, sie zu lenken:
Weg von reinem Profitstreben hin zu einer stärkeren Nutzung von Data-Mining im Sinne des Gemeinwohls.
Weg vom Datensammeln um jeden Preis hin zu einem datensparsamen, gezielten, zweckgebundenen und zielgerichteten Umgang insbesondere mit personenbezogenen Daten.
Weg vom Wilden Westen, in dem Hersteller von Produkten jedes Byte an Nutzerinnen- und Nutzerdaten sammeln und auswerten durften, hin zu Regulierung wie dem Data Act, der die Hoheit über die Daten dahin zurückgibt, wo sie hingehören, nämlich zu den Nutzerinnen und Nutzern.
Weg vom Datenvollzugriff für die Forschung in der elektronischen Patientenakte hin zu feingranularen Auswahlmöglichkeiten. Wir entscheiden, wer unsere Daten bekommt.
Und weg von proprietären Algorithmen mit unbekannten Trainingsdaten hin zu einer Kennzeichnungspflicht für maschinell erstellte Inhalte, Bilder oder Videos.
Data-Mining ist mächtig, aber noch mächtiger sind Data-Mining-Anwendungen im Zusammenspiel mit Vertrauen und Transparenz. Und das ist die digitale Zukunft, in der wir leben wollen.
Herzlichen Dank.