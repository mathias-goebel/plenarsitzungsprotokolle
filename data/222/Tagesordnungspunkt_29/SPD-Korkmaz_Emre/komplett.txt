Sehr geehrte Frau Präsidentin! Meine Damen und Herren! Die Bundesregierung betont in der Fortschreibung der KI-Strategie den Regulierungsbedarf für künstliche Intelligenz. Deshalb ist es sehr passend, dass in dieser Woche der Regulierungsvorschlag der EU öffentlich wurde. Was wir da allerdings in Teilen lesen dürfen, Stand heute, ist ziemlich zahnlos, inkonsequent und in weiten Teilen gefährlich.
Hochrisikoanwendungen müssen demnach eine Konformitätsprüfung durch Dritte bestehen. So weit, so gut. In vielen Fällen jedoch reicht dafür eine Selbstauskunft der Hersteller. So ist das zum Beispiel bei der Lernsoftware zur Überprüfung der Kreditwürdigkeit, beim Predictive Policing im Asylverfahren und auch zur Unterstützung der Rechtsprechung. Da sage ich: Das ist ziemlich krass. Darüber hinaus wird eine allgemeine Überwachung von KI-Systemen zwar erst einmal verboten, es sei denn, öffentliche Stellen halten sie für nötig. Da sage ich: Das ist mehr als krass, das ist gefährlich.
Viele verstehen die Diskussion nicht. Sogar der Berliner Zoo macht sich auf den Weg und will durch Gesichtserkennung Warteschlangen ersparen. Wieso nicht? Klingt ja erst mal praktisch. Aber nein, verdammt noch mal, zum Mitschreiben: Biometrische Gesichtserkennung ist grundrechtsfeindlich.
Es kommt nicht darauf an, wer sie einsetzt. Wir geben damit so oder so wieder ein Stück Privatheit und Selbstbestimmung auf.
Deshalb kann ich an dieser Stelle nur erneut die KI-Enquete-Sondervoten der SPD-Fraktion zur Lektüre empfehlen. Für die Einstufung von KI brauchen wir einen differenzierten, risikobasierten Ansatz, wie ihn auch die Datenethikkommission schon vorgeschlagen hat.
Dabei zeigt die Datenschutz-Grundverordnung schon den Weg auf. Ausgehend von den Zwecken einer Datenverarbeitung werden Risiken identifiziert, angemessene Maßnahmen abgeleitet und schon beim Entwickeln implementiert. Die Instrumente dafür haben wir. Das nennt sich Data Protection und Data Security by Design. Verdammt noch mal, Datenschutz ist kein Hemmschuh.
Verantwortungsvolle Technologiepolitik schützt Bürgerinnen und Bürger vor potenziellem Missbrauch.
Die Datenschutz-Grundverordnung ist dabei das Versprechen, dass Technologie unsere Werte der analogen Welt beinhaltet. Was diesen nicht genügt, und das gilt auch für zum Beispiel – aus aktuellem Anlass – die Luca-App, darf eben nicht zugelassen werden. Wer sich dann noch mehrfach falsch äußert oder billigend Sicherheitslücken in Kauf nimmt, sollte auch nicht mit Steuermitteln unterstützt werden. Vertrauen allein, etwa in die Selbstverpflichtung von Herstellern, macht am Ende keine gute Technologie. Das gilt auch und gerade für KI. Der Gesetzgeber macht die Vorgaben, nicht die Technologie und auch kein Rapper.
Vielen Dank.Sehr geehrte Frau Präsidentin! Meine Damen und Herren! Die Bundesregierung betont in der Fortschreibung der KI-Strategie den Regulierungsbedarf für künstliche Intelligenz. Deshalb ist es sehr passend, dass in dieser Woche der Regulierungsvorschlag der EU öffentlich wurde. Was wir da allerdings in Teilen lesen dürfen, Stand heute, ist ziemlich zahnlos, inkonsequent und in weiten Teilen gefährlich.
Hochrisikoanwendungen müssen demnach eine Konformitätsprüfung durch Dritte bestehen. So weit, so gut. In vielen Fällen jedoch reicht dafür eine Selbstauskunft der Hersteller. So ist das zum Beispiel bei der Lernsoftware zur Überprüfung der Kreditwürdigkeit, beim Predictive Policing im Asylverfahren und auch zur Unterstützung der Rechtsprechung. Da sage ich: Das ist ziemlich krass. Darüber hinaus wird eine allgemeine Überwachung von KI-Systemen zwar erst einmal verboten, es sei denn, öffentliche Stellen halten sie für nötig. Da sage ich: Das ist mehr als krass, das ist gefährlich.
Viele verstehen die Diskussion nicht. Sogar der Berliner Zoo macht sich auf den Weg und will durch Gesichtserkennung Warteschlangen ersparen. Wieso nicht? Klingt ja erst mal praktisch. Aber nein, verdammt noch mal, zum Mitschreiben: Biometrische Gesichtserkennung ist grundrechtsfeindlich.
Es kommt nicht darauf an, wer sie einsetzt. Wir geben damit so oder so wieder ein Stück Privatheit und Selbstbestimmung auf.
Deshalb kann ich an dieser Stelle nur erneut die KI-Enquete-Sondervoten der SPD-Fraktion zur Lektüre empfehlen. Für die Einstufung von KI brauchen wir einen differenzierten, risikobasierten Ansatz, wie ihn auch die Datenethikkommission schon vorgeschlagen hat.
Dabei zeigt die Datenschutz-Grundverordnung schon den Weg auf. Ausgehend von den Zwecken einer Datenverarbeitung werden Risiken identifiziert, angemessene Maßnahmen abgeleitet und schon beim Entwickeln implementiert. Die Instrumente dafür haben wir. Das nennt sich Data Protection und Data Security by Design. Verdammt noch mal, Datenschutz ist kein Hemmschuh.
Verantwortungsvolle Technologiepolitik schützt Bürgerinnen und Bürger vor potenziellem Missbrauch.
Die Datenschutz-Grundverordnung ist dabei das Versprechen, dass Technologie unsere Werte der analogen Welt beinhaltet. Was diesen nicht genügt, und das gilt auch für zum Beispiel – aus aktuellem Anlass – die Luca-App, darf eben nicht zugelassen werden. Wer sich dann noch mehrfach falsch äußert oder billigend Sicherheitslücken in Kauf nimmt, sollte auch nicht mit Steuermitteln unterstützt werden. Vertrauen allein, etwa in die Selbstverpflichtung von Herstellern, macht am Ende keine gute Technologie. Das gilt auch und gerade für KI. Der Gesetzgeber macht die Vorgaben, nicht die Technologie und auch kein Rapper.
Vielen Dank.