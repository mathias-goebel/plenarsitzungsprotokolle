Sehr geehrte Frau Präsidentin! Liebe Kolleginnen und Kollegen! Es ist gut, dass wir heute über „Künstliche Intelligenz made in Europe“ sprechen; denn wir reden hier darüber, dass in Europa Standards für eine Zukunftstechnologie definiert werden. Für uns ist klar: Das ist der eine Teil; insgesamt kann das aber nur gelingen, wenn wir natürlich auch stark in der Entwicklung und Anwendung von künstlicher Intelligenz sind. Das sind zwei Dinge, die gehören zusammen, und dafür setzen wir uns als Bundesregierung ein.
Deswegen hat diese Verordnung für uns eine sehr hohe Priorität. Und deswegen kann ich die hier formulierte Aufforderung, uns da einzubringen, gar nicht nachvollziehen. Diese Bundesregierung hat bereits dreimal eine Stellungnahme – geeint zwischen allen Ressorts – eingebracht gegenüber der EU-Kommission, der Ratspräsidentschaft.
Wir bringen uns sehr aktiv ein in diese Verordnung, weil wir um ihre große Bedeutung wissen und weil sie der Schlüssel ist für einen starken Standort für künstliche Intelligenz in Europa.
Die Punkte sind ja völlig richtig. Wir müssen pragmatisch sein. Deswegen ist es richtig, dass sich gerade die Definition weiterentwickelt. Mit dem aktuellsten Vorschlag werden nicht mehr sämtliche statistischen Systeme erfasst; es geht um maschinelles Lernen und um Expertensysteme, aber nicht mehr um jedes Programm, das in irgendeiner Form eine Rechnung durchführt. Das ist richtig. Diesen pragmatischen Ansatz unterstützen wir ebenso wie den Umstand, dass nicht mehr drinsteht, dass jeder Datensatz fehlerfrei sein muss, in dieser Absolutheit. Der neue Vorschlag geht in die Richtung: soweit eben möglich. Also Pragmatismus in der Umsetzung ist definitiv wichtig und auch unser Anliegen.
Auch Innovationen – das ist der andere Teil – werden mit der Verordnung unterstützt. Die Idee von Reallaboren, in denen man Dinge ausprobieren kann, auch Regulierungen ausprobieren kann, ist explizit Teil des Entwurfs. Das ist etwas, was von Deutschland sehr starke Unterstützung findet. Das heißt, Start-up-Freundlichkeit hat für uns hohe Priorität; das ist auch etwas, was wir einbringen.
Dann möchte ich zum Punkt „Hochrisiko“ kommen, der gerade noch groß in der Debatte ist. Für welche Teile trifft er zu, für welche nicht? Erst einmal möchte ich betonen: Es ist richtig, dass zwei Dinge ausgeschlossen sind, nämlich Social Scoring und die Live-Fernüberwachung. Das sind Dinge, die nicht akzeptabel und nicht mit den EU-Werten vereinbar sind.
Natürlich geht es bei Hochrisikoanwendungen darum, einen Standard zu haben. Da müssen wir draufschauen. Was passiert da? Wir brauchen Transparenzregeln und Qualitätsanforderungen. Hochrisikoanwendungen werden eben nicht verboten, sondern es gibt Standards. Natürlich ist es richtig, dass diese Standards für verschiedene Anwendungen im Gesundheitsbereich gelten müssen. Natürlich ist es richtig, dass sie zum Beispiel für den Zugang zu Wohnungen gelten müssen, wenn so was mit KI gemacht wird. Das ist ein Vorschlag, den wir einbringen: dass wir da die Dinge zum Teil erweitern. Da muss man draufschauen. KI muss natürlich fair, nachvollziehbar, transparent sein. Das ist der Sinn der Standards bei Hochrisikoanwendungen.
Das Ganze muss einhergehen mit der nötigen Unterstützung. Das ist klar. In der Digitalstrategie haben wir ein Programm für Unternehmen aufgelegt: Kickstart. Wir verbessern die Datenverfügbarkeit, die zentral ist für die Anwendungen von KI. Das heißt, wir haben beides auf dem Schirm: eine kluge Regulierung, aber auch die nötige Unterstützung für Innovationen im Bereich KI. Und daraus wird eine gute künstliche Intelligenz made in Europe werden.