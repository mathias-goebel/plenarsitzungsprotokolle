<rede id="ID205712500">
				<p klasse="redner">
					<redner id="11003848">
						<name>
							<titel>Dr.</titel>
							<vorname>Petra</vorname>
							<nachname>Sitte</nachname>
							<fraktion>DIE LINKE</fraktion>
						</name>
					</redner>Dr. Petra Sitte (DIE LINKE):</p>
				<p klasse="J_1">Frau Präsidentin! Meine Damen und Herren! Künstliche Intelligenz ist keine Zukunftstechnologie mehr. Längst begegnet sie uns täglich, und die meisten rechnen noch nicht einmal damit. Vor allem wissen sie nicht, dass der Einsatz und die Nutzung der KI im Moment nahezu im rechtsfreien Raum stattfinden. Das ist problematisch, weil nicht selten Grundrechte berührt sind. Es ist höchste Zeit, entsprechende Regelungen zu treffen. Auf EU‑Ebene – die Kollegen haben es gesagt – passiert das gerade. Diese Verordnung soll dann auch für Deutschland gelten.</p>
				<p klasse="J">Das Problem ist nur: Diese Verordnung hinterlässt mehr Lücken, als sie wirklich Dinge regelt. Mal wieder haben Lobbygruppen den Vorrang gehabt,</p>
				<kommentar>(Maximilian Mordhorst [FDP]: Natürlich!)</kommentar>
				<p klasse="O">und wir finden, dass das dem gesamten Vorhaben schadet. Was ist gemeint? Da ist erstens die Definition – Frau Christmann hat es gerade erwähnt –: Was wird unter KI oder – besser – unter maschinellem Lernen verstanden? Je enger die Auslegung ist, desto mehr bleibt für andere Systeme ungeklärt, insbesondere für Systeme, die einfach nur nach festen Regeln entscheiden.</p>
				<p klasse="J">Schon heute gibt es maschinelle Systeme in öffentlichen Einrichtungen, zum Beispiel bei Sozialversicherungen, in der Bundesagentur für Arbeit oder bei den Rentenversicherungen. Wir meinen, gerade solche Systeme, die der Staat einsetzt, sollten als sogenannte Hochrisikosysteme gelten. Dann – völlig klar – müssen besonders hohe Anforderungen an Transparenz und Nachvollziehbarkeit erfüllt werden. Und für uns gehört auch dazu, dass diese Systeme in einem öffentlichen Register aufgelistet werden. Somit kann dann jeder jederzeit sehen, wo eigentlich welches System zum Einsatz kommt. Wir finden, das ist eine wichtige vertrauensbildende Maßnahme.</p>
				<p klasse="J">Zweitens will die Bundesregierung die KI‑Nutzung in Sicherheitsbehörden gesondert regeln. Das wiederum sorgt weniger für Transparenz, und es ist auch nicht wirklich vertrauensbildend. Mithin haben wir es hier mit einem besonders grundrechtssensiblen Bereich zu tun. Beispielsweise könnte sich doch wieder eine Hintertür für die Gesichtserkennung öffnen. Ich finde schon, dass das, was im Koalitionsvertrag steht – Sie haben es selber angesprochen –, auch weiterhin Gültigkeit haben sollte. Biometrische Erkennungen im öffentlichen Raum, so heißt es da sinngemäß, sind europarechtlich auszuschließen. Genau dabei soll es bleiben.</p>
				<kommentar>(Beifall bei der LINKEN)</kommentar>
				<p klasse="J">Schließlich und drittens. Nehmen Sie die Anbieter mit in die Verantwortung. Es kann doch nicht ernsthaft sein, dass Innovationsförderung eine Freifahrt dafür sein kann, dass Unternehmen, gleich welcher Größe, von solchen Entscheidungen, von solchen Pflichten ausgenommen werden. Auch auf diese Unternehmen muss vertraut werden können. Vertrauen – ganz klar – entsteht durch Transparenz und natürlich –</p>
				<name>Vizepräsidentin Yvonne Magwas:</name>
				<p klasse="J_1">Bitte kommen Sie zum Schluss.</p>
				<p klasse="redner">
					<redner id="11003848">
						<name>
							<titel>Dr.</titel>
							<vorname>Petra</vorname>
							<nachname>Sitte</nachname>
							<fraktion>DIE LINKE</fraktion>
						</name>
					</redner>Dr. Petra Sitte (DIE LINKE):</p>
				<p klasse="J_1">– mache ich – durch Verlässlichkeit.</p>
				<kommentar>(Beifall bei der LINKEN)</kommentar>
				<name>Vizepräsidentin Yvonne Magwas:</name>
				<p klasse="J_1">Für die FDP-Fraktion hat das Wort der Kollege Maximilian Funke-Kaiser.</p>
				<kommentar>(Beifall bei der FDP sowie bei Abgeordneten der SPD und des BÜNDNISSES 90/DIE GRÜNEN)</kommentar>
			</rede>