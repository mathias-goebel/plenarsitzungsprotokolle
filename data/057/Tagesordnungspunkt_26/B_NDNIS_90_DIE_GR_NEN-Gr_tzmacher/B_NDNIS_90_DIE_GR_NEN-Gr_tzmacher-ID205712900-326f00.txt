Sehr geehrte Frau Präsidentin! Sehr geehrte Kolleginnen und Kollegen! Sehr geehrte Damen und Herren! Wir haben gerade gehört: Wir müssen Vertrauen schaffen. – Ich kann Ihnen sagen, wie man Vertrauen schafft: Wenn man dafür sorgt, dass nicht permanent etwas kaputtgeht. Ich erinnere an die Zeugnis-Blockchain. Wenn das die vertrauensbildenden Maßnahmen sind, die Sie sich vorstellen, dann sehe ich da tatsächlich schwarz.
Ich glaube, im Kern sind wir uns einig: KI soll den Nutzen für die Gesellschaft in den Mittelpunkt stellen. Aber Gesellschaft ist mehr als Wirtschaft. Gesellschaft, das sind Menschen in all ihrer Vielfalt, und dazu gehören auch vulnerable Gruppen. In der Anhörung zum AI‑Act machte der Sachverständige Herr Geuter deutlich: Zu oft wird über Vorstellungen und Fantasien der Zukunft geredet, die nicht auf wirklichen Eigenschaften oder Strukturen basieren.
Aber KI liefert nicht auf magische Weise automatisch Mehrwert. Das zeigt Ihr Beispiel zum angeblich erfolgreichen KI‑Einsatz in der Pandemie. Es gibt eine Metastudie des MIT. Es fand unter über 100 Anwendungen keine einzige erfolgreiche KI‑Anwendung. Aber ich verstehe trotzdem den Punkt; denn ja, gute KI kann Innovation hervorbringen. Wir müssen aber anfangen, zwischen Algorithmen, künstlicher Intelligenz, Machine Learning, Deep Learning und zukünftigen Ansätzen wie Quantum Machine Learning zu unterscheiden und auch diese Entwicklung zu ermöglichen.
Wir müssen uns da auch ehrlich machen; denn Zukunftstechnologien machen nicht per se alles besser, weil Buzzwords auf dem Etikett stehen. Sie machen es besser, wenn echte KI‑Anwendungen enthalten sind und passende Technologien für passende Szenarien ausgewählt werden.
KI‑Anwendungen sind mehr als die Summe ihrer Teile, und wir müssen kombinierte Einsätze bewerten, nicht nur Branchen und Segmente. Und: Sie müssen sicher sein; denn wenn Regierungen nicht in der Lage sind, Zukunftstechnologien sicher zu machen, dann verlieren wir alle das Vertrauen der Bürgerinnen und Bürger. Wohin das führt, hat die Sachverständige Catelijne Muller von der Organisation ALLAI in der Anhörung berichtet. So ist die Regierung Rutte der VVD aufgrund eines KI‑Systems, das über 20 000 Bürgerinnen und Bürger des Betrugs bezichtigt hat, zurückgetreten. Dieser Ausgang war vermutlich nicht Teil der Risikobetrachtung.
Die KI‑Verordnung liefert hier einen für die EU zukunftsweisenden Vorschlag, an dem natürlich noch weiter gearbeitet werden kann. Aber die deutsche Stellungnahme ergänzt sinnvolle Punkte wie die Frage nach Möglichkeiten der Sammel- und Verbandsklage und die Absage an biometrische Live-Fernüberwachung auch im nichtöffentlichen Raum. Auch die Forderungen des Koalitionsvertrags nach Wahrung von Bürgerrechten oder Diskriminierungsfreiheit werden eingearbeitet.
Ähnlich wie die DSGVO – sie ist eigentlich ein Erfolgsmodell – bietet sich die Möglichkeit eines europäischen Markenkerns; denn Technikfolgenabschätzung und sichere KI als europäisches Konzept, das ist gelebte Wirtschaftsförderung, weil Wirtschaft rechtsverbindlich und sicher planen kann.
Wenn dann bei der Zusammensetzung des zu schaffenden AI‑Boards vielleicht auch noch die digitale Zivilgesellschaft mit am Tisch sitzen dürfte, dann wären wir sogar noch einen Schritt weiter. Ich bin guter Dinge, dass wir das gemeinsam beraten bekommen.
Vielen herzlichen Dank.